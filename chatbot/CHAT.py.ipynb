{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ad9516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import BotNet\n",
    "from NLP_utils import  tokenize, vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "541730fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9630a4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}]}\n"
     ]
    }
   ],
   "source": [
    "with open('intents.json') as f:\n",
    "    intents = json.load(f)\n",
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd3c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = torch.load('model_data.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8102c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_state': OrderedDict([('l1.weight',\n",
       "               tensor([[ 1.3122e-01,  5.0160e-01,  2.9121e-01,  2.0012e-01,  2.5023e-01,\n",
       "                        -3.4425e-01,  2.6551e-01,  3.6705e-01,  3.0112e-01,  3.0404e-01,\n",
       "                         2.8029e-01,  1.0778e+00,  5.8040e-01,  1.3554e+00,  9.9235e-01,\n",
       "                         6.2345e-01,  1.1974e-01, -3.4496e-01,  1.9986e-01,  4.4243e-01,\n",
       "                         1.6162e-01,  3.6768e-01,  1.8246e-01,  6.2506e-01,  6.0200e-01,\n",
       "                         9.9741e-02,  2.9302e-01,  1.5313e+00,  1.2276e-01,  1.1695e+00,\n",
       "                        -3.8056e-01,  1.1781e+00,  1.6394e-01,  1.1420e-01,  1.3406e+00,\n",
       "                         6.5790e-01,  2.9523e-02,  2.6489e-01,  2.2217e-01,  3.2410e-02,\n",
       "                        -3.0384e-01,  2.5107e-01,  9.5452e-01,  1.0009e+00,  7.2026e-01,\n",
       "                         1.1591e+00,  3.3690e-01, -4.2684e-02,  7.8434e-02,  2.2048e-01,\n",
       "                         8.3019e-01,  2.2628e-01,  2.0369e-01,  3.3412e-01],\n",
       "                       [ 3.2939e-01,  3.2527e-02,  3.6001e-01,  3.0084e-01,  1.0154e-01,\n",
       "                        -3.4509e-01,  7.8983e-02, -8.7849e-03,  3.5130e-01,  2.2127e-01,\n",
       "                         1.7895e-01,  1.2443e+00,  2.2948e-01,  1.4595e+00, -1.6106e-01,\n",
       "                         1.0397e+00,  1.1056e-01, -3.4707e-01,  1.5603e-01,  1.6063e-01,\n",
       "                         5.8136e-02,  1.1577e-01,  3.8359e-01,  7.1850e-01,  5.7335e-01,\n",
       "                         2.7065e-01,  2.7311e-01, -4.2187e-01,  1.3621e-01, -3.6636e-01,\n",
       "                        -3.1833e-01,  1.3317e+00,  4.9544e-01,  3.0830e-01, -1.6620e-01,\n",
       "                         8.8904e-01,  1.2449e-01,  2.1431e-01,  8.3860e-02,  1.4597e-01,\n",
       "                        -1.9756e-01,  1.4654e-01,  1.1066e+00, -7.1578e-02,  5.3049e-01,\n",
       "                         4.3725e-02,  4.0869e-01, -7.7456e-02,  3.1470e-01,  3.8348e-01,\n",
       "                         9.0317e-01,  2.8621e-01,  7.7282e-02,  1.7134e-01],\n",
       "                       [-6.2834e-02,  5.8308e-01,  3.5364e-02,  2.5189e-01,  3.4011e-01,\n",
       "                        -3.2506e-01,  2.0109e-01,  4.1215e-02,  9.6118e-02,  2.8154e-01,\n",
       "                        -2.2935e-03, -2.7005e-01,  3.6774e-01, -1.6698e-01,  7.6602e-01,\n",
       "                        -1.5463e-01, -4.0630e-02, -3.2293e-01,  1.2418e-02,  4.5669e-02,\n",
       "                         1.6077e-01,  3.4178e-01,  1.0555e-01,  2.8643e-01,  1.8646e-02,\n",
       "                         1.8886e-01,  8.2050e-02,  1.7628e+00,  1.7510e-01,  1.6363e+00,\n",
       "                        -2.4289e-01, -2.6033e-01, -1.3582e-01,  1.5737e-01,  1.0697e+00,\n",
       "                        -6.3131e-02,  1.2943e-01,  1.0870e-01,  8.8712e-02,  1.7876e-01,\n",
       "                        -2.7236e-01,  1.0161e-01, -2.6557e-01,  8.9996e-01,  8.3146e-02,\n",
       "                         1.1421e+00,  1.6071e-01,  8.8710e-02,  2.2179e-01,  7.1300e-02,\n",
       "                        -2.3502e-01,  1.5708e-01,  1.8454e-01,  1.7778e-01],\n",
       "                       [-5.5052e-02,  6.8417e-01, -9.0206e-02, -3.8998e-02, -3.0476e-02,\n",
       "                        -3.5086e-01, -4.2609e-02, -2.9077e-01, -1.7223e-02, -2.9682e-01,\n",
       "                        -6.4533e-02,  1.3308e+00,  5.9798e-01,  1.3257e+00,  7.8881e-01,\n",
       "                         1.0233e+00, -4.5568e-03, -3.5553e-01, -1.2982e-01,  1.3638e-01,\n",
       "                        -2.3881e-02,  3.2163e-01,  3.7543e-01,  6.8894e-01,  7.4294e-01,\n",
       "                        -6.9446e-02, -4.7057e-02,  1.5744e+00, -1.6023e-01,  1.2617e+00,\n",
       "                        -2.5197e-01,  1.3992e+00, -7.7439e-02, -1.1593e-01,  9.8502e-01,\n",
       "                         8.2729e-01,  8.9424e-03, -1.7915e-02, -2.3266e-01, -2.3500e-01,\n",
       "                        -8.9578e-02, -1.3717e-01,  1.0106e+00,  5.8700e-01,  3.8714e-01,\n",
       "                         9.2300e-01,  1.6482e-01,  1.6176e-02, -6.1690e-02, -1.3825e-01,\n",
       "                         8.3120e-01, -1.1472e-01, -5.3388e-02, -1.4385e-02],\n",
       "                       [-1.9211e-01, -1.7406e-01, -1.1503e-01, -6.6071e-04, -2.7206e-01,\n",
       "                         1.6926e+00, -2.7406e-01, -1.7260e-01,  1.0183e-01, -1.3430e-01,\n",
       "                        -2.2026e-01,  1.0776e+00,  2.2143e-01,  1.4679e+00, -1.6788e-01,\n",
       "                         9.4670e-01, -7.3528e-02,  1.7373e+00, -1.2126e-03, -3.1788e-01,\n",
       "                        -8.9039e-02, -3.1343e-01, -3.7648e-01,  6.1014e-01,  5.8163e-01,\n",
       "                        -1.3264e-02, -6.3871e-02, -4.5210e-02, -2.1294e-02, -4.3873e-02,\n",
       "                         5.4442e-02,  1.3047e+00, -4.9893e-02, -8.4045e-02, -1.7397e-01,\n",
       "                         8.4770e-01,  1.0349e-01, -7.2457e-02, -2.5452e-02, -1.6449e-01,\n",
       "                        -1.1651e-01, -1.4038e-02,  1.1388e+00, -1.5401e-02,  3.3610e-01,\n",
       "                        -1.4811e-01, -3.9167e-01, -8.4299e-02, -1.8921e-01,  2.5511e-02,\n",
       "                         1.0446e+00,  4.8808e-02, -1.3722e-01, -4.6378e-01],\n",
       "                       [-4.1145e-02, -3.4231e-01, -1.7363e-02, -1.1825e-01, -1.4592e-01,\n",
       "                         1.8315e+00, -1.3138e-01, -2.5074e-01, -1.6779e-01, -2.3866e-01,\n",
       "                        -2.3632e-01,  1.0795e+00,  4.6278e-02,  1.0066e+00, -2.7702e-01,\n",
       "                         7.7287e-01, -9.0767e-02,  1.7996e+00, -9.3708e-02, -2.7281e-01,\n",
       "                         5.5806e-02, -1.7672e-01, -3.5327e-01,  3.0425e-01,  3.7840e-01,\n",
       "                        -1.5114e-01, -4.9922e-02, -4.9155e-01,  7.6660e-04, -3.8187e-01,\n",
       "                         1.5889e+00,  8.8590e-01, -7.1626e-02, -2.3653e-01, -1.9468e-01,\n",
       "                         6.5763e-01, -6.9483e-02, -3.0988e-02, -1.6251e-01, -2.3347e-01,\n",
       "                         1.5404e+00, -1.7210e-01,  7.2607e-01, -2.1529e-01,  4.5591e-01,\n",
       "                        -1.6692e-01, -4.4781e-01, -2.2031e-02, -1.1983e-01, -1.6908e-01,\n",
       "                         6.5411e-01, -1.3261e-01, -1.1405e-01,  3.1560e-01],\n",
       "                       [ 2.1515e-01, -1.5396e-01,  5.6652e-02, -2.8307e-02, -5.8937e-02,\n",
       "                        -1.3594e-01,  2.4306e-01,  1.2129e-01, -7.7485e-02,  1.1210e-01,\n",
       "                         3.1872e-01,  1.7925e-02, -6.6868e-02, -1.8215e-02, -9.5259e-02,\n",
       "                         6.3195e-02,  2.5855e-01, -1.2148e-01, -4.4503e-03,  3.8922e-01,\n",
       "                         1.8165e-01,  1.7872e-01,  1.0697e-01,  6.4944e-02,  1.8221e-01,\n",
       "                        -1.3455e-01, -2.8585e-02, -7.4105e-02, -1.2655e-01, -6.2296e-02,\n",
       "                        -1.1657e-01, -1.0317e-01, -9.0146e-02, -5.0075e-02, -2.6477e-02,\n",
       "                        -6.1629e-02, -1.1661e-01, -3.1534e-02,  8.9111e-02,  1.2589e-01,\n",
       "                        -4.0716e-02,  3.0126e-02, -8.3758e-02,  9.8089e-02, -8.6399e-02,\n",
       "                        -1.2780e-01, -1.0484e-01,  1.9705e-01, -1.0252e-01,  3.5725e-03,\n",
       "                         2.1229e-02, -1.0284e-01,  1.1219e-01, -7.6468e-02],\n",
       "                       [-3.2073e-01,  4.4646e-01, -1.4031e-01, -1.3676e-03,  7.0046e-03,\n",
       "                         1.3701e+00,  1.2274e-01, -1.4139e-01, -1.4182e-01, -2.3530e-02,\n",
       "                        -1.7633e-02, -1.4846e-01,  2.3810e-01, -1.2841e-01,  1.0043e+00,\n",
       "                        -1.9200e-01, -6.5592e-02,  1.3521e+00, -2.1817e-01, -1.4712e-01,\n",
       "                        -1.0308e-01, -3.0188e-01, -9.4743e-02,  2.8710e-02, -1.6967e-01,\n",
       "                        -1.8786e-01, -1.5113e-01,  1.6828e+00,  1.8781e-02,  1.5030e+00,\n",
       "                         1.1559e+00, -1.9522e-01, -3.4835e-01, -2.6176e-01,  1.2811e+00,\n",
       "                        -5.9251e-02, -2.9667e-02, -2.0160e-01,  1.3271e-03, -8.5566e-02,\n",
       "                         9.1130e-01, -1.2118e-01, -7.2885e-02,  9.8884e-01, -1.3863e-01,\n",
       "                         1.4290e+00, -2.6402e-01,  3.3735e-02, -2.1025e-02, -2.1873e-01,\n",
       "                        -1.8429e-01, -4.3010e-03,  7.5367e-02,  2.5571e-01]])),\n",
       "              ('l1.bias',\n",
       "               tensor([0.3399, 0.3437, 0.3166, 0.3428, 0.4876, 0.8355, 0.1207, 0.4885])),\n",
       "              ('l2.weight',\n",
       "               tensor([[-0.4744, -0.4784, -0.1617, -0.8049,  0.6734,  1.1653, -0.2754,  0.7207],\n",
       "                       [ 0.1171,  0.6451, -0.7509,  0.5123,  1.4560,  1.1282, -0.6906, -0.0072],\n",
       "                       [-0.3027, -0.2048, -0.3299,  0.3499, -0.2005,  0.1907, -0.2310, -0.2281],\n",
       "                       [ 0.6660, -0.3555,  0.9223,  0.6593, -0.5822, -0.5964,  0.0914,  1.2544],\n",
       "                       [ 0.6179,  0.6455, -0.0585,  0.9896,  0.2205,  0.0853,  0.4420, -0.3509],\n",
       "                       [-0.1326, -0.1017, -0.1270,  0.0842, -0.0935,  0.0367, -0.0454,  0.0771],\n",
       "                       [ 0.2596, -0.3365, -0.1952,  0.0228, -0.3467, -0.3054, -0.2882, -0.1622],\n",
       "                       [ 0.5500,  0.8481,  0.0744,  0.0942, -0.2001,  0.1018,  0.8430, -0.6914]])),\n",
       "              ('l2.bias',\n",
       "               tensor([ 0.7434,  0.7487, -0.2124,  0.5578, -0.1278, -0.3785, -0.2527,  0.4436])),\n",
       "              ('l3.weight',\n",
       "               tensor([[-0.6327,  0.5933, -0.1315, -0.8386,  0.4120, -0.0226,  0.0800, -0.0715],\n",
       "                       [-0.5002, -0.7818,  0.1682,  0.9720,  0.0531,  0.0592, -0.1876, -0.6635],\n",
       "                       [ 1.5071,  0.9562, -0.2605, -0.2264, -0.8954, -0.2763, -0.2894, -1.0693],\n",
       "                       [ 0.2483, -0.2617,  0.2947, -0.1786,  0.2731,  0.0760, -0.2536, -0.3522],\n",
       "                       [ 0.2256, -0.2094,  0.3296, -0.3783, -0.1784,  0.0205,  0.1658,  0.3228],\n",
       "                       [-0.1517, -0.2155, -0.3197, -0.0755, -0.3108,  0.1521,  0.2599,  0.1865],\n",
       "                       [ 0.1495, -0.1203, -0.1478, -0.3350, -0.0817, -0.0342, -0.0422, -0.1175]])),\n",
       "              ('l3.bias',\n",
       "               tensor([-0.1362,  0.4651,  0.6881, -0.2232, -0.1171, -0.3512, -0.2462]))]),\n",
       " 'input_size': 54,\n",
       " 'output_size': 7,\n",
       " 'hidden_size': 8,\n",
       " 'total_words': [\"'s\",\n",
       "  'a',\n",
       "  'accept',\n",
       "  'anyon',\n",
       "  'are',\n",
       "  'bye',\n",
       "  'can',\n",
       "  'card',\n",
       "  'cash',\n",
       "  'credit',\n",
       "  'day',\n",
       "  'deliveri',\n",
       "  'do',\n",
       "  'doe',\n",
       "  'funni',\n",
       "  'get',\n",
       "  'good',\n",
       "  'goodby',\n",
       "  'have',\n",
       "  'hello',\n",
       "  'help',\n",
       "  'hey',\n",
       "  'hi',\n",
       "  'how',\n",
       "  'i',\n",
       "  'is',\n",
       "  'item',\n",
       "  'joke',\n",
       "  'kind',\n",
       "  'know',\n",
       "  'later',\n",
       "  'long',\n",
       "  'lot',\n",
       "  'mastercard',\n",
       "  'me',\n",
       "  'my',\n",
       "  'of',\n",
       "  'onli',\n",
       "  'pay',\n",
       "  'paypal',\n",
       "  'see',\n",
       "  'sell',\n",
       "  'ship',\n",
       "  'someth',\n",
       "  'take',\n",
       "  'tell',\n",
       "  'thank',\n",
       "  'that',\n",
       "  'there',\n",
       "  'what',\n",
       "  'when',\n",
       "  'which',\n",
       "  'with',\n",
       "  'you'],\n",
       " 'tags': ['delivery',\n",
       "  'funny',\n",
       "  'goodbye',\n",
       "  'greeting',\n",
       "  'items',\n",
       "  'payments',\n",
       "  'thanks']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5bf8efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_state', 'input_size', 'output_size', 'hidden_size', 'total_words', 'tags'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e4ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state = model_data['model_state']\n",
    "input_size = model_data['input_size']\n",
    "output_size = model_data['output_size']\n",
    "hidden_size = model_data['hidden_size']\n",
    "total_words = model_data['total_words']\n",
    "tags = model_data['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12abfdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BotNet(\n",
       "  (l1): Linear(in_features=54, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_model = BotNet(input_size, hidden_size, output_size)\n",
    "bot_model.load_state_dict(model_state)\n",
    "bot_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ff33060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask anything!and type quit to exit.\n",
      "You: hi\n",
      "test_bot: Have a nice day\n",
      "You: hi there\n",
      "test_bot: What did the buffalo say when his son left for college? Bison.\n",
      "You: what do you sell\n",
      "test_bot: Delivery takes 2-4 days\n",
      "You: thanks\n",
      "test_bot: Delivery takes 2-4 days\n",
      "You: who are you\n",
      "test_bot: See you later, thanks for visiting\n",
      "You: ok thanks\n",
      "test_bot: Shipping takes 2-4 days\n",
      "You: i am amit\n",
      "test_bot: Bye! Come back again soon.\n",
      "You: ok\n",
      "test_bot: Have a nice day\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "bot_name = 'test_bot'\n",
    "print(f'Ask anything!and type quit to exit.')\n",
    "\n",
    "while True:\n",
    "    sent = input('You: ')\n",
    "    if sent == 'quit':\n",
    "        break\n",
    "    sent_tok = tokenize(sent)\n",
    "    sent_vec = vectorize(sent_tok, total_words)\n",
    "    sent_vec =sent_vec.reshape(1,-1)\n",
    "    sent_vec = torch.from_numpy(sent_vec).to(device).float()\n",
    "    \n",
    "    out = bot_model(sent_vec)\n",
    "    prob_of_out = torch.softmax(out,dim=1)\n",
    "    _,pred = torch.max(out,dim=1)\n",
    "    prob = prob_of_out[0][pred.item()]\n",
    "    #print(prob.item(),prob_of_out[0])\n",
    "    if prob.item() > 0.2:\n",
    "        for intent in intents['intents']:\n",
    "            if tags[pred.item()] == intent['tag']:\n",
    "                print(f'{bot_name}: {random.choice(intent[\"responses\"])}')\n",
    "                \n",
    "    else:\n",
    "        print(f'{bot_name}: I do not understand...')\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11278230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
